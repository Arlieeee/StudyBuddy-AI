"""Recommendation service for generating visualization topic suggestions."""
from typing import List, Optional, Dict, Any
from pydantic import BaseModel

from .rag_service import get_rag_service
from .gemini_client import get_gemini_client
from .keyword_extractor import get_keyword_extractor


class VisualizationTopic(BaseModel):
    """A recommended visualization topic."""
    type: str  # "overview", "concept", "chapter"
    title: str
    description: str
    prompt: str  # The actual prompt to use for image generation


class RecommendationService:
    """Service for generating smart recommendations based on RAG and conversation history."""
    
    async def get_visualization_topics(
        self,
        document_ids: Optional[List[str]] = None,
        conversation_history: Optional[List[Dict[str, str]]] = None,
    ) -> List[VisualizationTopic]:
        """
        Generate visualization topic recommendations.
        
        Analyzes uploaded documents and conversation history to suggest
        relevant topics for diagram/visualization generation.
        
        Args:
            document_ids: Optional list of document IDs to analyze
            conversation_history: List of {"role": "user"|"assistant", "content": "..."}
        
        Returns:
            List of recommended visualization topics
        """
        rag = get_rag_service()
        gemini = get_gemini_client()
        keyword_extractor = get_keyword_extractor()
        
        # Get document summaries
        documents = rag.list_documents()
        if document_ids:
            documents = [d for d in documents if d["id"] in document_ids]
        
        if not documents:
            # No documents, return default suggestions
            return [
                VisualizationTopic(
                    type="overview",
                    title="è¯·å…ˆä¸Šä¼ å­¦ä¹ èµ„æ–™",
                    description="ä¸Šä¼  PDF æˆ–æ–‡æ¡£åŽï¼Œæˆ‘ä¼šæ ¹æ®å†…å®¹æŽ¨èå¯è§†åŒ–ä¸»é¢˜",
                    prompt=""
                )
            ]
        
        # Get sample content from documents for analysis
        doc_samples = []
        all_content_for_keywords = []  # Collect content for TF-IDF analysis
        
        for doc in documents[:3]:  # Limit to 3 documents
            results = await rag.search(
                query="ä¸»è¦å†…å®¹æ¦‚è¿°",
                top_k=2,
                document_ids=[doc["id"]]
            )
            if results:
                content = "\n".join([r["text"][:500] for r in results])
                doc_samples.append({
                    "filename": doc["filename"],
                    "content": content
                })
                all_content_for_keywords.append(content)
        
        # === NEW: TF-IDF Keyword Extraction ===
        extracted_keywords = []
        if all_content_for_keywords:
            try:
                extracted_keywords = keyword_extractor.get_trending_topics(
                    all_content_for_keywords, 
                    top_n=15
                )
                print(f"[Recommendation] Extracted TF-IDF keywords: {extracted_keywords}")
            except Exception as e:
                print(f"[Recommendation] Keyword extraction failed: {e}")
        
        # Analyze conversation for frequently mentioned concepts
        frequent_concepts = ""
        if conversation_history:
            # Extract user messages
            user_messages = [
                m["content"] for m in conversation_history 
                if m.get("role") == "user" and m.get("content")
            ][-10:]  # Last 10 messages
            if user_messages:
                frequent_concepts = "\n".join(user_messages)
        
        # Build prompt for Gemini to generate recommendations
        keywords_section = ""
        if extracted_keywords:
            keywords_section = f"\n## ðŸ”‘ TF-IDF æå–çš„é«˜é¢‘å…³é”®è¯\n{', '.join(extracted_keywords[:15])}\n"
        
        prompt = f"""åŸºäºŽä»¥ä¸‹å­¦ä¹ èµ„æ–™å’Œç”¨æˆ·å¯¹è¯åŽ†å²ï¼Œç”Ÿæˆ5ä¸ªé€‚åˆåˆ¶ä½œå¯è§†åŒ–å›¾è§£çš„ä¸»é¢˜æŽ¨èã€‚

## å­¦ä¹ èµ„æ–™å†…å®¹æ‘˜è¦
{chr(10).join([f"### {s['filename']}{chr(10)}{s['content']}" for s in doc_samples]) if doc_samples else "æš‚æ— èµ„æ–™æ‘˜è¦"}
{keywords_section}
## ç”¨æˆ·è¿‘æœŸæé—®/å…³æ³¨æ¦‚å¿µ
{frequent_concepts if frequent_concepts else "æš‚æ— å¯¹è¯åŽ†å²"}

## è¦æ±‚
è¯·åŸºäºŽä¸Šè¿°**å…³é”®è¯**å’Œèµ„æ–™å†…å®¹ï¼Œç”Ÿæˆ5ä¸ªå¯è§†åŒ–ä¸»é¢˜æŽ¨èï¼Œæ¯ä¸ªä¸»é¢˜åŒ…å«ï¼š
1. type: ç±»åž‹ï¼Œåªèƒ½æ˜¯ "overview"(å…¨å±€æ¦‚è§ˆ)ã€"concept"(å…·ä½“æ¦‚å¿µ)ã€"chapter"(ç« èŠ‚æ€»ç»“) ä¹‹ä¸€
2. title: ç®€çŸ­æ ‡é¢˜ï¼ˆ10å­—ä»¥å†…ï¼‰ï¼Œå¿…é¡»åŒ…å«å…³é”®è¯ä¸­çš„æ ¸å¿ƒæ¦‚å¿µ
3. description: æè¿°ï¼ˆ20å­—ä»¥å†…ï¼‰
4. prompt: ç”¨äºŽç”Ÿæˆå›¾è§£çš„å®Œæ•´æç¤ºè¯

è¿”å›žJSONæ•°ç»„æ ¼å¼ï¼Œä¾‹å¦‚ï¼š
[
  {{"type": "overview", "title": "å…¨å±€çŸ¥è¯†æ¡†æž¶", "description": "æ•´ä½“çŸ¥è¯†ç»“æž„æ¦‚è§ˆ", "prompt": "ç”Ÿæˆå…³äºŽ[ä¸»é¢˜]çš„å…¨å±€çŸ¥è¯†ç»“æž„æ€ç»´å¯¼å›¾"}},
  {{"type": "concept", "title": "æ ¸å¿ƒç®—æ³•å¯¹æ¯”", "description": "æ¯”è¾ƒä¸åŒç®—æ³•ç‰¹ç‚¹", "prompt": "ç”Ÿæˆ[ç®—æ³•A]ä¸Ž[ç®—æ³•B]çš„å¯¹æ¯”æµç¨‹å›¾"}}
]

åªè¿”å›žJSONæ•°ç»„ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""

        try:
            response = await gemini.generate_text(
                prompt=prompt,
                system_instruction="ä½ æ˜¯ä¸€ä¸ªå­¦ä¹ åŠ©æ‰‹ï¼Œè´Ÿè´£åˆ†æžå­¦ä¹ èµ„æ–™å¹¶æŽ¨èé€‚åˆå¯è§†åŒ–çš„çŸ¥è¯†ç‚¹ã€‚åªè¿”å›žæœ‰æ•ˆçš„JSONæ•°ç»„ã€‚"
            )
            
            # Parse response
            import json
            # Clean response - remove markdown code blocks if present
            text = response.strip()
            if text.startswith("```"):
                text = text.split("\n", 1)[1] if "\n" in text else text
            if text.endswith("```"):
                text = text.rsplit("```", 1)[0]
            if text.startswith("json"):
                text = text[4:].strip()
            
            topics_data = json.loads(text)
            
            topics = []
            for item in topics_data[:5]:  # Limit to 5
                topics.append(VisualizationTopic(
                    type=item.get("type", "concept"),
                    title=item.get("title", "æœªå‘½åä¸»é¢˜"),
                    description=item.get("description", ""),
                    prompt=item.get("prompt", item.get("title", ""))
                ))
            
            return topics
            
        except Exception as e:
            print(f"Error generating recommendations: {e}")
            # Return fallback recommendations based on document names
            topics = []
            for doc in documents[:3]:
                topics.append(VisualizationTopic(
                    type="overview",
                    title=f"{doc['filename'][:15]}æ¦‚è§ˆ",
                    description="æ•´ä½“çŸ¥è¯†ç»“æž„",
                    prompt=f"ç”Ÿæˆå…³äºŽ{doc['filename']}çš„çŸ¥è¯†ç»“æž„æ€ç»´å¯¼å›¾"
                ))
            if not topics:
                topics.append(VisualizationTopic(
                    type="overview",
                    title="çŸ¥è¯†æ¡†æž¶æ€»è§ˆ",
                    description="æ‰€æœ‰å­¦ä¹ èµ„æ–™çš„æ•´ä½“ç»“æž„",
                    prompt="ç”Ÿæˆå­¦ä¹ èµ„æ–™çš„æ•´ä½“çŸ¥è¯†æ¡†æž¶æ€ç»´å¯¼å›¾"
                ))
            return topics



    async def get_chat_topics(
        self,
        document_ids: Optional[List[str]] = None,
        conversation_history: Optional[List[Dict[str, str]]] = None,
    ) -> List[VisualizationTopic]:
        """
        Generate chat topic recommendations.
        
        Args:
            document_ids: Optional list of document IDs
            conversation_history: User conversation history
            
        Returns:
            List of recommended chat topics/questions
        """
        rag = get_rag_service()
        gemini = get_gemini_client()
        
        # Get document summaries
        documents = rag.list_documents()
        if document_ids:
            documents = [d for d in documents if d["id"] in document_ids]
            
        if not documents:
            return [
                VisualizationTopic(
                    type="summary",
                    title="è¯·å…ˆä¸Šä¼ æ–‡æ¡£",
                    description="ä¸Šä¼ æ–‡æ¡£åŽï¼Œæˆ‘å¯ä»¥å¸®ä½ æ€»ç»“å†…å®¹æˆ–å›žç­”é—®é¢˜",
                    prompt=""
                )
            ]
            
        # Get sample content
        doc_samples = []
        for doc in documents[:3]:
            # Use specific samples or just first chunk
            doc_samples.append({
                "filename": doc["filename"],
                "content": f"Document: {doc['filename']}" # Minimal context needed for generic questions, but better if we have content
            })
            # Try to get some actual content if possible, reusing logic from visualization
            results = await rag.search(query="summary", top_k=1, document_ids=[doc["id"]])
            if results:
                 doc_samples[-1]["content"] += f"\nContent: {results[0]['text'][:800]}"

        # Analyze history
        recent_context = ""
        if conversation_history:
            user_msgs = [m["content"] for m in conversation_history if m.get("role") == "user"][-5:]
            if user_msgs:
                recent_context = "\n".join(user_msgs)

        prompt = f"""åŸºäºŽä»¥ä¸‹æ–‡æ¡£å†…å®¹å’Œç”¨æˆ·å¯¹è¯ï¼Œç”Ÿæˆ4ä¸ªå€¼å¾—æé—®çš„é—®é¢˜æˆ–æŒ‡ä»¤æŽ¨èã€‚
        
## æ–‡æ¡£æ‘˜è¦
{chr(10).join([f"### {s['filename']}{chr(10)}{s['content']}" for s in doc_samples])}

## ç”¨æˆ·è¿‘æœŸå¯¹è¯
{recent_context if recent_context else "æ— "}

## è¦æ±‚
ç”Ÿæˆ4ä¸ªæŽ¨èï¼Œè¦†ç›–ä»¥ä¸‹ç±»åž‹ï¼š
1. summary (æ–‡æ¡£æ‘˜è¦)
2. concept (è§£é‡Šæ ¸å¿ƒæ¦‚å¿µ)
3. qa (é’ˆå¯¹å…·ä½“ç»†èŠ‚æé—®)
4. review (ç”Ÿæˆå¤ä¹ é¢˜)

è¿”å›žJSONæ•°ç»„ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
[
  {{"type": "summary", "title": "æ€»ç»“æ–‡æ¡£å†…å®¹", "description": "å¿«é€Ÿäº†è§£æ ¸å¿ƒè§‚ç‚¹", "prompt": "è¿™ä»½æ–‡æ¡£çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ"}},
  {{"type": "concept", "title": "è§£é‡Š[æŸæ¦‚å¿µ]", "description": "æ·±å…¥ç†è§£æ ¸å¿ƒæ¦‚å¿µ", "prompt": "è¯·è§£é‡Šä¸€ä¸‹[æŸæ¦‚å¿µ]çš„å®šä¹‰å’ŒåŽŸç†"}},
  {{"type": "qa", "title": "å…³äºŽ[æŸç»†èŠ‚]", "description": "æŽ¢ç´¢æ–‡æ¡£å…·ä½“ç»†èŠ‚", "prompt": "å…³äºŽ[æŸæŠ€æœ¯]æœ‰ä»€ä¹ˆå…³é”®ç‚¹ï¼Ÿ"}},
  {{"type": "review", "title": "ç”Ÿæˆå¤ä¹ é¢˜", "description": "å·©å›ºçŸ¥è¯†ç‚¹", "prompt": "åŸºäºŽæ–‡æ¡£å†…å®¹ç”Ÿæˆ3é“å¤ä¹ æ€è€ƒé¢˜"}}
]
ç¡®ä¿promptæ˜¯ç”¨æˆ·å¯ä»¥ç›´æŽ¥å‘é€ç»™AIçš„é—®é¢˜ã€‚åªè¿”å›žJSONæ•°ç»„ã€‚"""

        try:
            response = await gemini.generate_text(prompt=prompt)
            # Parse JSON logic similar to above
            import json
            text = response.strip()
            if text.startswith("```"):
                text = text.split("\n", 1)[1] if "\n" in text else text
            if text.endswith("```"):
                text = text.rsplit("```", 1)[0]
            if text.startswith("json"):
                text = text[4:].strip()
                
            topics_data = json.loads(text)
            topics = []
            for item in topics_data[:4]:
                topics.append(VisualizationTopic(
                    type=item.get("type", "qa"),
                    title=item.get("title", "æŽ¨èé—®é¢˜"),
                    description=item.get("description", ""),
                    prompt=item.get("prompt", "")
                ))
            return topics
        except Exception as e:
            print(f"Error chat recommendations: {e}")
            # Fallback
            return [
                VisualizationTopic(type="summary", title="æ€»ç»“å…¨æ–‡", description="ç”Ÿæˆæ–‡æ¡£æ‘˜è¦", prompt="è¿™ä»½æ–‡æ¡£ä¸»è¦è®²äº†ä»€ä¹ˆï¼Ÿ"),
                VisualizationTopic(type="review", title="ç”Ÿæˆè€ƒé¢˜", description="æµ‹è¯•çŸ¥è¯†æŽŒæ¡", prompt="åŸºäºŽæ–‡æ¡£ç”Ÿæˆ5ä¸ªå¤ä¹ é¢˜"),
            ]


# Global service instance
_recommendation_service: Optional[RecommendationService] = None



def get_recommendation_service() -> RecommendationService:
    """Get or create recommendation service instance."""
    global _recommendation_service
    if _recommendation_service is None:
        _recommendation_service = RecommendationService()
    return _recommendation_service
